{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Comedy...\n",
      "20/20 movies scrapped !!!\n",
      "40/40 movies scrapped !!!\n",
      "60/60 movies scrapped !!!\n",
      "79/80 movies scrapped !!!\n",
      "99/100 movies scrapped !!!\n",
      "100/101 movies scrapped !!!\n",
      "All movies scrapped !!!\n",
      "Processing Romance...\n",
      "19/20 movies scrapped !!!\n",
      "29/40 movies scrapped !!!\n",
      "44/60 movies scrapped !!!\n",
      "59/80 movies scrapped !!!\n",
      "73/100 movies scrapped !!!\n",
      "85/120 movies scrapped !!!\n",
      "100/140 movies scrapped !!!\n",
      "100/140 movies scrapped !!!\n",
      "All movies scrapped !!!\n"
     ]
    }
   ],
   "source": [
    "csv.register_dialect('myDialect',delimiter=',', quoting=csv.QUOTE_ALL,skipinitialspace=True)\n",
    "\n",
    "movie_data = []\n",
    "genre_list = [\n",
    "#     'Action',\n",
    "#     'Adventure',\n",
    "#     'Animation',\n",
    "#     'Biography',\n",
    "    'Comedy',\n",
    "#     'Crime',\n",
    "#     'Drama',\n",
    "#     'Fantasy',\n",
    "#     'History',\n",
    "#     'Horror',\n",
    "#     'Music',\n",
    "#     'Mystery',\n",
    "    'Romance',\n",
    "#     'Sci-Fi',\n",
    "#     'Sport',\n",
    "#     'Thriller',\n",
    "#     'War',\n",
    "#     'Western'\n",
    "]\n",
    "cwd = os.getcwd()\n",
    "# if os.path.exists(cwd + \"/1_movies_per_genre\"):\n",
    "#     shutil.rmtree(\"1_movies_per_genre\", ignore_errors=True)\n",
    "\n",
    "# os.makedirs(\"1_movies_per_genre\")\n",
    "num_movies_to_scrape = 100\n",
    "for idx, genre in enumerate(genre_list):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    page_ctr = 0\n",
    "    with open(f\"1_movies_per_genre/{genre}.csv\", \"w\") as f:\n",
    "        print(f\"Processing {genre}...\")\n",
    "        while(j < num_movies_to_scrape):\n",
    "            top_50_url = 'https://www.imdb.com/search/title/?title_type=feature&genres={}&sort=num_votes,desc&explore=genres&start={}'.format(genre.lower(), page_ctr*50 + 1)\n",
    "            page = requests.get(top_50_url, headers = {\"Accept-Language\": \"en-US, en;q=0.5\"})\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            table_body = soup.find_all('div', 'lister-item mode-advanced')\n",
    "            writer = csv.writer(f, dialect='myDialect')\n",
    "            #write this only for the first page\n",
    "            if page_ctr == 0:\n",
    "                writer.writerow(['name', 'year', 'movie_rated', 'run_length', 'genres', 'release_date', 'rating', 'num_raters', 'num_reviews', 'review_url'])\n",
    "            #Break if movie list is empty\n",
    "            if not table_body or i>=1000 :\n",
    "                print(f\"{j}/{i} movies scrapped !!!\")\n",
    "                print(\"50 movies not found in this genre !!!\")\n",
    "                break\n",
    "            for table_row in table_body:\n",
    "                i += 1\n",
    "                rating_url = 'https://www.imdb.com' + table_row.find('div', 'lister-item-content').find('h3', 'lister-item-header').a['href'].split('?')[0]\n",
    "                review_url = rating_url + 'reviews/_ajax?ref_=undefined&paginationKey='\n",
    "                page = requests.get(rating_url, headers = {\"Accept-Language\": \"en-US, en;q=0.5\"})\n",
    "                soup = BeautifulSoup(page.content, 'html.parser')\n",
    "                title_wrapper = soup.find('div', 'title_wrapper')\n",
    "                name = (str(title_wrapper.h1.contents[0])).split('<span')[0]\n",
    "                name = name.split('\\xa0')[0]\n",
    "                year = int(title_wrapper.h1.span.a.contents[0])\n",
    "                rating_value = soup.find('div', 'ratingValue')\n",
    "                rating_value = str(rating_value.contents[1]).split('\"')\n",
    "                rating = float(rating_value[1].split(' ')[0])\n",
    "                num_raters = rating_value[1].split('on ')[1]\n",
    "                num_raters = int(num_raters.split(' ')[0].replace(',', ''))\n",
    "\n",
    "                subtext = title_wrapper.find('div', 'subtext')\n",
    "                movie_rated = str(subtext.contents[0]).split('<span')[0]\n",
    "                movie_rated = movie_rated.replace('\\n', ' ')\n",
    "                movie_rated = movie_rated.strip(' ')\n",
    "                run_length = subtext.time.contents[0]\n",
    "                run_length = run_length.replace('\\n', ' ')\n",
    "                run_length = run_length.strip(' ')\n",
    "                a_href = subtext.find_all('a')\n",
    "                genres = \"\"\n",
    "                release_date = \"\"\n",
    "                top_3_genres = \"\"\n",
    "                genre_count = 0\n",
    "                for a in a_href:\n",
    "                    if str(a.contents[0]) in genre_list:\n",
    "                        genres = genres + str(a.contents[0]) + \"; \"\n",
    "                        if genre_count < 3:\n",
    "                            top_3_genres = top_3_genres + str(a.contents[0]) + \"; \"\n",
    "                            genre_count+=1\n",
    "                    else:\n",
    "                        release_date = str(a.contents[0])\n",
    "                release_date = release_date.replace('\\n', ' ')\n",
    "                release_date = release_date.strip(' ')\n",
    "\n",
    "                num_reviews = 0\n",
    "                num_revs = soup.find('div', 'user-comments')\n",
    "                a_href = num_revs.find_all('a')\n",
    "                for a in a_href:\n",
    "                    if (str(a.contents).find('See all my') != -1):\n",
    "                        continue\n",
    "                    if (str(a.contents).find('See all ') != -1):\n",
    "                        num_reviews = str(a.contents).split('See all ')[1]\n",
    "                        num_reviews = num_reviews.split(' user reviews')[0]\n",
    "                        num_reviews = int(num_reviews.replace(',', ''))\n",
    "\n",
    "                if len(movie_rated) == 0:\n",
    "                    movie_rated = 'Null'\n",
    "                if len(run_length) == 0:\n",
    "                    run_length = 'Null'\n",
    "                if len(genres) == 0:\n",
    "                    genres = 'Null'\n",
    "                if len(release_date) == 0:\n",
    "                    release_date = 'Null'\n",
    "\n",
    "                movie_data = [name, year, movie_rated, run_length, genres, release_date, rating, num_raters, num_reviews, review_url]\n",
    "                name = name.replace('/', '_')\n",
    "                #print (movie_data)\n",
    "                #If genre is not present in top 3 genres\n",
    "                if genre in top_3_genres:\n",
    "#                     if (genre == 'Comedy' and 'Romance' in genres) or (genre == 'Romance' and 'Comedy' in genres):\n",
    "#                         continue\n",
    "                    if (int(num_reviews) >= num_movies_to_scrape):\n",
    "                        j += 1\n",
    "                        writer.writerow(movie_data)\n",
    "                if (i%20 == 0):\n",
    "                    print(f\"{j}/{i} movies scrapped !!!\")\n",
    "                    f.flush()\n",
    "                if j >= 100:\n",
    "                    print(f\"{j}/{i} movies scrapped !!!\")\n",
    "                    print(\"All movies scrapped !!!\")\n",
    "                    break\n",
    "            page_ctr += 1\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
