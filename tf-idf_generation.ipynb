{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from stemming.porter2 import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181 Jurassic Park 1993</td>\n",
       "      <td>year hollywood film jurassic park dinosaurs br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181 Jurassic Park 1993</td>\n",
       "      <td>adapted book unique story destined incredible ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181 Jurassic Park 1993</td>\n",
       "      <td>loved movie utter amazement brachiosaurus eat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181 Jurassic Park 1993</td>\n",
       "      <td>jurassic park american science fiction adventu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181 Jurassic Park 1993</td>\n",
       "      <td>epic movie big screen jurassic park years idea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                                             review\n",
       "0  181 Jurassic Park 1993  year hollywood film jurassic park dinosaurs br...\n",
       "1  181 Jurassic Park 1993  adapted book unique story destined incredible ...\n",
       "2  181 Jurassic Park 1993  loved movie utter amazement brachiosaurus eat ...\n",
       "3  181 Jurassic Park 1993  jurassic park american science fiction adventu...\n",
       "4  181 Jurassic Park 1993  epic movie big screen jurassic park years idea..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_files = os.listdir('reviews_per_genre')\n",
    "for genre_file in genre_files:\n",
    "    if (genre_file != 'Thriller.csv'): continue # uncomment line to test one genre\n",
    "    file_data = pd.read_csv('reviews_per_genre/' + genre_file)\n",
    "    reviews = file_data['review']\n",
    "file_data.head()\n",
    "#print (str(len(reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['misnam', 'mirabil', 'mirac', 'mirimax', 'mirren', 'mirth', 'misbehav', 'misc', 'miscarriag', 'miscellan', 'misconduct', 'misshapen', 'minnesotta', 'misslead']\n",
      "Topic 0:\n",
      "film enjoy recommend excel brilliant fan love view amaz masterpiec\n",
      "Topic 1:\n",
      "batman bane nolan wayn gotham bruce catwoman bale trilog gordon\n",
      "Topic 2:\n",
      "movi love recommend amaz enjoy definit better theater plot favorit\n",
      "Topic 3:\n",
      "scorses depart nicholson damon dicaprio costello martin jack matt wahlberg\n",
      "Topic 4:\n",
      "tarantino dog reservoir pulp fiction quentin madsen keitel roth heist\n",
      "Topic 5:\n",
      "donni darko frank gyllenha jake rabbit kelli travel bunni teenag\n",
      "Topic 6:\n",
      "shark jaw spielberg brodi quint shaw water beach hooper dreyfuss\n",
      "Topic 7:\n",
      "willi sixth osment cole bruce haley sens joel shyamalan boy\n",
      "Topic 8:\n",
      "bourn ultimatum jason damon cia supremaci matt greengrass chase trilog\n",
      "Topic 9:\n",
      "leonard memento memori pearc wife nolan backward guy rememb term\n",
      "Topic 10:\n",
      "runner blade replic deckard ford scott harrison human ridley sci\n",
      "Topic 11:\n",
      "hopkin lecter hannib foster claric lamb jodi silenc anthoni starl\n",
      "Topic 12:\n",
      "die hard mcclane willi john rickman bruce terrorist alan gruber\n",
      "Topic 13:\n",
      "park dinosaur jurass spielberg effect rex goldblum steven hammond special\n",
      "Topic 14:\n",
      "action sequenc pack hero flick drama explos plot dialogu fan\n",
      "Topic 15:\n",
      "bardem coen chigurh jone brolin countri tommi javier lee men\n",
      "Topic 16:\n",
      "leon mathilda portman reno oldman natali jean besson gari luc\n",
      "Topic 17:\n",
      "pacino niro heat mann deniro kilmer michael robert val cop\n",
      "Topic 18:\n",
      "psycho norman bate hitchcock perkin horror marion shower leigh motel\n",
      "Topic 19:\n",
      "best oscar actor perform nomin pictur deserv award year perfect\n",
      "Topic 20:\n",
      "island shutter scorses teddi dicaprio daniel patient marshal ruffalo kingsley\n",
      "Topic 21:\n",
      "spacey kevin suspect usual soze verbal kint keyser byrn twist\n",
      "Topic 22:\n",
      "great act stori actor job cast direct script perform love\n",
      "Topic 23:\n",
      "room jack larson tremblay brie mother jacob joy son year\n",
      "Topic 24:\n",
      "tarantino kill bride uma thurman reveng volum quentin fight blood\n",
      "Topic 25:\n",
      "watch worth love enjoy dvd understand recommend feel ago fun\n",
      "Topic 26:\n",
      "good act pretti stori actor bit thing better job bad\n",
      "Topic 27:\n",
      "hitchcock window rear stewart grant jeff suspens apart jame northwest\n",
      "Topic 28:\n",
      "fargo coen mcdormand brother maci franc jerri buscemi marg kidnap\n",
      "Topic 29:\n",
      "murder milland kelli dial toni grace hitchcock ray wife margot\n",
      "Topic 30:\n",
      "vertigo scotti stewart hitchcock novak madelein kim obsess judi jame\n",
      "Topic 31:\n",
      "chinatown gitt polanski nicholson dunaway noir mulwray jake jack fay\n",
      "Topic 32:\n",
      "war german das boot submarin boat crew version cut captain\n",
      "Topic 33:\n",
      "knight dark rise nolan trilog christoph joker hardi bale tom\n",
      "Topic 34:\n",
      "brando terri waterfront kazan marlon saint malloy malden cobb steiger\n",
      "Topic 35:\n",
      "charact stori feel work life audienc plot viewer man main\n",
      "Topic 36:\n",
      "scene fight shot cut music camera open final shower chase\n",
      "Topic 37:\n",
      "peopl bad guy bore rate review thing understand plot lot\n",
      "Topic 38:\n",
      "origin infern affair depart remak version hong kong better cut\n",
      "Topic 39:\n",
      "time favorit second long love greatest travel wast view perfect\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-dee164a4d56e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mno_top_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mdisplay_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_top_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mdisplay_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_feature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_top_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;31m# Run LDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m#lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lda' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "no_topics = 40\n",
    "no_top_words = 10\n",
    "\n",
    "genre_files = os.listdir('reviews_per_genre')\n",
    "for genre_file in genre_files:\n",
    "    if (genre_file != 'Thriller.csv'): continue # uncomment line to test one genre\n",
    "    file_data = pd.read_csv('reviews_per_genre/' + genre_file)\n",
    "    reviews = file_data['review']\n",
    "    reviews1 = pd.Series.tolist(reviews)\n",
    "    reviews1 = [[stem(word) for word in sentence.split(\" \")] for sentence in reviews]\n",
    "    reviews = []\n",
    "    for review in reviews1:\n",
    "        reviews.append(' '.join(review))\n",
    "    \n",
    "    '''# CountVectorizer\n",
    "    \n",
    "    vect = CountVectorizer(min_df=2, stop_words=\"english\")\n",
    "    vect1 = vect.fit_transform(reviews)\n",
    "    #pd.DataFrame(vect1.toarray(), index=reviews, columns=vect.get_feature_names()).head(10)\n",
    "    print (\"Vocabulary size: {}\".format(len(vect.vocabulary_)))\n",
    "    #print (\"Vocabulary content:\\n {}\".format(vect.vocabulary_))\n",
    "    \n",
    "    # Bag of Words\n",
    "    \n",
    "    bag_of_words = vect.transform(reviews)\n",
    "    #print (\"bag_of_words: {}\".format(repr(bag_of_words)))\n",
    "    \n",
    "    # Feature Extraction\n",
    "    \n",
    "    feature_names = vect.get_feature_names()\n",
    "    #print(\"Number of features: {}\".format(len(feature_names)))'''\n",
    "    \n",
    "    try:\n",
    "        tfidf_vect = TfidfVectorizer(min_df=2, stop_words='english')\n",
    "        tfidf_vect = tfidf_vect.fit(reviews)\n",
    "        features = tfidf_vect.get_feature_names()\n",
    "        indices = np.argsort(tfidf_vect.idf_)[::-1]\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    top_n = 15\n",
    "    top_features = [features[i] for i in indices[1:top_n]]\n",
    "    print (top_features)\n",
    "    \n",
    "    tfidf = tfidf_vect.fit_transform(reviews)\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=top_n, stop_words='english')\n",
    "    tf = tf_vectorizer.fit_transform(reviews)\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    \n",
    "    # Bag of Words\n",
    "    \n",
    "    bag_of_words = tf_vectorizer.transform(reviews)\n",
    "    #print (\"bag_of_words: {}\".format(repr(bag_of_words)))\n",
    "    \n",
    "    # Run NMF\n",
    "    nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "#     with open('NMF/genres/'+genre_file[:-4], 'w') as f:\n",
    "#         for topic_idx, topic in enumerate(nmf.components_):\n",
    "#             for i in topic.argsort()[:-no_top_words - 1:-1]:\n",
    "#                 f.write(features[i]+'\\n')\n",
    "    \n",
    "    def display_topics(model, feature_names, no_top_words):\n",
    "        for topic_idx, topic in enumerate(model.components_):\n",
    "            print (\"Topic %d:\" % (topic_idx))\n",
    "            print (\" \".join([feature_names[i]\n",
    "                            for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "    no_top_words = 10\n",
    "    display_topics(nmf, features, no_top_words)\n",
    "    display_topics(lda, tf_feature_names, no_top_words)\n",
    "    # Run LDA\n",
    "    #lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horror\t\t59440669655040.0\n",
      "Sci-Fi\t\t116095057920.0\n",
      "Music\t\t82556485632.0\n",
      "Western\t\t57330892800.0\n",
      "War\t\t41278242816.0\n",
      "Mystery\t\t17199267840.0\n",
      "Thriller\t\t12899450880.0\n",
      "Action\t\t5662310400.0\n",
      "History\t\t2579890176.0\n",
      "Romance\t\t1274019840.0\n",
      "Film-Noir\t\t1146617856.0\n",
      "Adventure\t\t716636160.0\n",
      "Biography\t\t716636160.0\n",
      "Drama\t\t530841600.0\n",
      "Sport\t\t509607936.0\n",
      "Animation\t\t382205952.0\n",
      "Crime\t\t335923200.0\n",
      "Fantasy\t\t199065600.0\n",
      "Musical\t\t82944000.0\n",
      "Family\t\t37748736.0\n",
      "Comedy\t\t552960.0\n",
      "['052 Alien 1979', '033 Psycho 1960', '223 Diabolique 1955', '060 The Shining 1980', '031 Interstellar 2014', '181 Jurassic Park 1993', '207 Logan 2017', '109 Metropolis 1927', '039 The Pianist 2002', '226 La La Land 2016', '044 Whiplash 2014', '061 Django Unchained 2012', '106 For a Few Dollars More 1965', '035 Once Upon a Time in the West 1968', '009 The Good, the Bad and the Ugly 1966']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "review = ''\n",
    "with open('input_review.txt', 'r') as f:\n",
    "    review = f.read()\n",
    "\n",
    "REPLACE_WITH_TWO_SPACES = \"(\\&)|(\\%)|(\\$)|(\\@)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\*)|(â€“)|([0-9]+)|(<br\\s*/><br\\s*/>)|(\\.)|(\\-)|(\\/)|(\\s+)|(\\n)\"\n",
    "REPLACE_WITH_SPACE = \"(\\s+)\"\n",
    "stopwords =[\"spoiler\", \"spoilers\"]\n",
    "with open('stopwords.txt', 'r') as stopwords_file:\n",
    "    for line in stopwords_file:\n",
    "        stop = line.replace('\\n', '')\n",
    "        stopwords.append(stop)\n",
    "'''import nltk.corpus\n",
    "for e in list(nltk.corpus.stopwords.words(\"english\")):\n",
    "    if e not in stopwords:\n",
    "        print (e)'''\n",
    "#print (stopwords)\n",
    "REPLACE_WORDS = \"( [a-z]{1,2} )|( [a-z]{20,} )\" # 1-2 charactered words & >= 20 charactered words\n",
    "FINAL = \"[^a-z\\s]\"\n",
    "#print (words_to_replace)\n",
    "\n",
    "review_clean = review.lower()\n",
    "review_clean = \" \" + review_clean + \" \"\n",
    "review_clean = review_clean.replace(\"'\", \"\")\n",
    "review_clean = re.sub(REPLACE_WITH_TWO_SPACES, \"  \", review_clean)\n",
    "for stopword in stopwords:\n",
    "    #STOP = \" \"+stopword.replace(\"'\",\"\")+\" \"\n",
    "    review_clean = review_clean.replace(\" \" + stopword.replace(\"'\",\"\") + \" \", \"  \")\n",
    "    #review_clean = re.sub(STOP, \"  \", review_clean)\n",
    "review_clean = re.sub(REPLACE_WORDS, \"  \", review_clean)\n",
    "#print (review_clean)\n",
    "review_clean = re.sub(REPLACE_WITH_SPACE, \" \", review_clean)\n",
    "review_clean = re.sub(FINAL, \"\", review_clean)\n",
    "review_clean = review_clean.strip()\n",
    "if (review_clean == 'null' or review_clean == ''):\n",
    "    print ('Review is null or full of stopwords')\n",
    "    exit(0)\n",
    "inp_dict = defaultdict(int)\n",
    "for word in review_clean.split():\n",
    "    inp_dict[stem(word)] += 1\n",
    "\n",
    "reviews = [stem(word) for word in review.split(\" \")]\n",
    "genre_files = os.listdir('NMF/genres')\n",
    "probs = {}\n",
    "for genre_file in genre_files:\n",
    "    d = defaultdict(int)\n",
    "    with open('NMF/genres/'+genre_file, 'r') as f:\n",
    "        genre_review = f.read().splitlines()\n",
    "        for r in genre_review:\n",
    "            d[r] += 1\n",
    "    bayesian_prob = 1\n",
    "    for key in inp_dict:\n",
    "        try:\n",
    "            value = inp_dict[key]\n",
    "            val = d[key]\n",
    "            if (value * val > 0):\n",
    "                bayesian_prob *= (value * val + 0.0)\n",
    "        except:\n",
    "            continue\n",
    "    probs[genre_file] = bayesian_prob\n",
    "sorted_keys = sorted(probs, key=probs.get, reverse=True)\n",
    "for key in sorted_keys:\n",
    "    print (key + \"\\t\\t\" + str(probs[key]))\n",
    "    \n",
    "#Take top 5 genres for a review and recommend top 4 movies of each genre!! \n",
    "genre_list = []\n",
    "count = 0\n",
    "for key in sorted_keys:\n",
    "    count+=1\n",
    "    if(count==5):\n",
    "        break\n",
    "    genre_list.append(key)\n",
    "\n",
    "recommended_movies = []\n",
    "for genre in genre_list:\n",
    "    movies = []\n",
    "    genre_df = pd.read_csv('reviews_per_genre/'+genre+'.csv')\n",
    "    movies = genre_df.name.unique()\n",
    "    ct = 0\n",
    "    for movie in movies:\n",
    "        ct+=1\n",
    "        if(ct==5):\n",
    "            break\n",
    "        recommended_movies.append(movie)\n",
    "print(recommended_movies)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.05491356 -1.31062149]\n",
      " [ 4.3276431  -1.31616716]\n",
      " [ 7.07766276 -2.32395652]\n",
      " ...\n",
      " [ 0.58175011  0.03963518]\n",
      " [ 4.27792354  4.15163211]\n",
      " [ 2.97190488 -0.01765916]]\n"
     ]
    }
   ],
   "source": [
    "vect1 = vect1.asfptype()\n",
    "lsa = TruncatedSVD(2, algorithm = 'arpack')\n",
    "tfidf_lsa = lsa.fit_transform(vect1)\n",
    "print (tfidf_lsa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
